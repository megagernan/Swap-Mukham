{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megagernan/mukham/blob/main/mukham_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bypvIQG5RHl9"
      },
      "source": [
        "# üóø **Swap-Mukham**\n",
        "*Face swap app based on insightface inswapper.*\n",
        "\n",
        "**–ö–æ–¥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å, –∑–∞–ø—É—Å–∫–∞—è –µ–≥–æ, –Ω–µ—Å–µ—Ç –ø–æ–ª–Ω—É—é –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —Å–æ–∑–¥–∞–≤–∞–µ–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏ —Å–æ–≥–ª–∞—à–∞–µ—Ç—Å—è —Å —ç—Ç–∏–º —É—Å–ª–æ–≤–∏–µ–º.**\n",
        "\n",
        "*The code is provided solely for educational purposes. The user who executes the code assumes full responsibility for the content created and agrees to this condition.*\n",
        "- [Github](https://github.com/megagernan/mukham)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csC_DX5zWLEU"
      },
      "source": [
        "# Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klcx2cKDKX5x"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "! git clone https://github.com/megagernan/mukham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bebBDddfWTXf"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgTpg7EsTN3o"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd Swap-Mukham/\n",
        "print(\"Installing requirements...\")\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install gdown\n",
        "print(\"Installing requirements done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9L6tgD0Wats"
      },
      "source": [
        "# Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17MZO9OvUQAk"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "inswapper_model = \"https://huggingface.co/ofter/4x-UltraSharp/resolve/main/inswapper_128.onnx\" #@param {type:\"string\"}\n",
        "gfpgan_model = \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\" #@param {type:\"string\"}\n",
        "face_parser_model = \"https://drive.google.com/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812\" #@param {type:\"string\"}\n",
        "real_esrgan_2x_model = \"https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth\" #@param {type:\"string\"}\n",
        "real_esrgan_4x_model = \"https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth\" #@param {type:\"string\"}\n",
        "real_esrgan_8x_model = \"https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x8.pth\" #@param {type:\"string\"}\n",
        "codeformer_model = \"https://huggingface.co/bluefoxcreation/Codeformer-ONNX/resolve/main/codeformer.onnx\" #@param {type:\"string\"}\n",
        "nsfw_det_model = \"https://huggingface.co/bluefoxcreation/open-nsfw/resolve/main/open-nsfw.onnx\" #@param {type:\"string\"}\n",
        "import gdown\n",
        "import urllib.request\n",
        "print(\"Downloading swapper model...\")\n",
        "urllib.request.urlretrieve(inswapper_model, \"/content/Swap-Mukham/assets/pretrained_models/inswapper_128.onnx\")\n",
        "print(\"Downloading gfpgan model...\")\n",
        "urllib.request.urlretrieve(gfpgan_model, \"/content/Swap-Mukham/assets/pretrained_models/GFPGANv1.4.pth\")\n",
        "print(\"Downloading face parsing model...\")\n",
        "gdown.download(face_parser_model, \"/content/Swap-Mukham/assets/pretrained_models/79999_iter.pth\")\n",
        "print(\"Downloading realesrgan 2x model...\")\n",
        "urllib.request.urlretrieve(real_esrgan_2x_model, \"/content/Swap-Mukham/assets/pretrained_models/RealESRGAN_x2.pth\")\n",
        "print(\"Downloading realesrgan 4x model...\")\n",
        "urllib.request.urlretrieve(real_esrgan_4x_model, \"/content/Swap-Mukham/assets/pretrained_models/RealESRGAN_x4.pth\")\n",
        "print(\"Downloading realesrgan 8x model...\")\n",
        "urllib.request.urlretrieve(real_esrgan_8x_model, \"/content/Swap-Mukham/assets/pretrained_models/RealESRGAN_x8.pth\")\n",
        "print(\"Downloading codeformer...\")\n",
        "urllib.request.urlretrieve(codeformer_model, \"/content/Swap-Mukham/assets/pretrained_models/codeformer.onnx\")\n",
        "print(\"Downloading NSFW detector model...\")\n",
        "urllib.request.urlretrieve(nsfw_det_model, \"/content/Swap-Mukham/assets/pretrained_models/open-nsfw.onnx\")\n",
        "print(\"Downloading models done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEcCUw0Co6bE"
      },
      "source": [
        "# Mount Google drive (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KssYYippDMw"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tn68Ayqdrlk"
      },
      "source": [
        "# Run App\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dpBjbfVOrrc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "default_output_path = \"/content/Swap-Mukham\" #@param {type:\"string\"}\n",
        "\n",
        "command = f\"python app.py --cuda --colab --out_dir {default_output_path}\"\n",
        "!{command}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}